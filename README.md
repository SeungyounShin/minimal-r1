### Why Minimal-R1?

I aimed to reproduce the original [R1 paper](https://github.com/deepseek-ai/DeepSeek-R1) using only an **8x H100 server**. However, during development, I encountered some limitations with open-r1 (though these may have been resolved now):

- **Token Generation Limit**: Open-r1 could not generate more than **256 completion tokens**, even with a 7B model. Since long-CoT (Chain-of-Thought) reasoning is a key novelty of R1, **long-form generation is essential**.
- **DeepSpeed ZeRO-3 Incompatibility**: Open-r1 did not work with **DeepSpeed ZeRO-3**, likely due to issues within `trl`.
- **Separated Generation & Reference Models**: Unlike open-r1, **Minimal-R1 runs generation and reference models on separate GPUs**, improving efficiency and scalability.

### GPU Allocation in Minimal-R1

| GPU        | Function      |
|------------|--------------|
| **gpu0-1**   | Generation   |
| **gpu2**   | Reference    |
| **gpu3â€“7** | Policy       |

By **separating generation and reference models**, Minimal-R1 ensures more efficient memory usage and parallel processing, optimizing the training workflow.

---

### How to Run

1) Install requirements

```bash
pip install -r requirements.txt
```

2) Launch the **vLLM server** and **reference model server**:

```bash
CUDA_VISIBLE_DEVICES=0,1 nohup python3 minimal_r1/launch_vllm.py --model_name Seungyoun/Qwen2.5-7B-Open-R1-Distill & > vllm.log &
CUDA_VISIBLE_DEVICES=2 nohup python3 minimal_r1/launch_ref_model.py --model_name Seungyoun/Qwen2.5-7B-Open-R1-Distill & > ref_model.log &
```

3) Then, start the training script:

```bash
CUDA_VISIBLE_DEVICES=3,4,5,6,7 nohup accelerate launch --config_file ./configs/zero3.yaml minimal_r1/train_grpo.py --max_tokens 4096 & > train.log &
```

This setup enables efficient training while addressing the original open-r1 limitations. ğŸš€

---

### Performance Analysis and Optimization

Below is a pie chart visualizing the **overall time distribution across all steps** during the training process:

![Time Distribution](misc/pie_chart.png)

As seen in the chart, the **generation step dominates the overall runtime, accounting for 71.0% of the time**. Given this, allocating more GPUs to the generation process could potentially improve efficiency and reduce the bottleneck. This adjustment may lead to faster training and better resource utilization, especially when handling long-form generation tasks.

---

# xDAN-RLAIF-GRPO

ä½¿ç”¨GRPO (Generative Reward Proximal Optimization)è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹çš„åˆ†å¸ƒå¼è®­ç»ƒæ¡†æ¶ã€‚

## ç‰¹ç‚¹

- åˆ†å¸ƒå¼è®­ç»ƒæ”¯æŒï¼ˆDeepSpeed + Accelerateï¼‰
- å¤šGPUå¼ é‡å¹¶è¡Œæ¨ç†ï¼ˆvLLMï¼‰
- å®Œæ•´çš„è®­ç»ƒã€ç”Ÿæˆå’Œè¯„ä¼°æµç¨‹
- çµæ´»çš„é…ç½®ç³»ç»Ÿ

## ç³»ç»Ÿè¦æ±‚

- Python 3.8+
- CUDA 11.7+
- è‡³å°‘3ä¸ªGPUèŠ‚ç‚¹ï¼ˆè®­ç»ƒã€ç”Ÿæˆã€å‚è€ƒï¼‰

## å¿«é€Ÿå¼€å§‹

1. é…ç½®èŠ‚ç‚¹ï¼ˆç¼–è¾‘`config/nodes.yaml`ï¼‰ï¼š
```yaml
training:
  master_node: "gpu007"
  services:
    generation:
      url: "http://gpu004:8000"
    reference:
      url: "http://gpu008:8001"
```

2. å¯åŠ¨æœåŠ¡ï¼š
```bash
# åœ¨gpu004ä¸Šå¯åŠ¨vLLMç”ŸæˆæœåŠ¡
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python src/launch_vllm.py \
    --model_path /path/to/model \
    --port 8000 \
    --tensor_parallel_size 8

# åœ¨gpu008ä¸Šå¯åŠ¨å‚è€ƒæ¨¡å‹æœåŠ¡
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python src/launch_ref_model.py \
    --model_path /path/to/model \
    --port 8001 \
    --tensor_parallel_size 8
```

3. å¯åŠ¨è®­ç»ƒï¼š
```bash
./scripts/launch_distributed.sh
```

## ç›®å½•ç»“æ„

```
é¡¹ç›®æ ¹ç›®å½•/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ nodes.yaml      # èŠ‚ç‚¹å’Œæ¨¡å‹é…ç½®
â”‚   â”œâ”€â”€ hostfile        # DeepSpeedè®­ç»ƒèŠ‚ç‚¹é…ç½®
â”‚   â””â”€â”€ accelerate_config.yaml  # Accelerateé…ç½®
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train_grpo.py   # è®­ç»ƒä¸»è„šæœ¬
â”‚   â”œâ”€â”€ launch_vllm.py  # vLLMæœåŠ¡å¯åŠ¨è„šæœ¬
â”‚   â””â”€â”€ launch_ref_model.py  # å‚è€ƒæ¨¡å‹æœåŠ¡å¯åŠ¨è„šæœ¬
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ launch_distributed.sh  # åˆ†å¸ƒå¼è®­ç»ƒå¯åŠ¨è„šæœ¬
â”‚   â””â”€â”€ launch_training.sh     # è®­ç»ƒå¯åŠ¨è„šæœ¬
â””â”€â”€ output/             # è®­ç»ƒè¾“å‡ºç›®å½•
    â”œâ”€â”€ checkpoints/   # æ¨¡å‹æ£€æŸ¥ç‚¹
    â””â”€â”€ logs/         # è®­ç»ƒæ—¥å¿—
```

## è®­ç»ƒé…ç½®

ä¸»è¦è®­ç»ƒå‚æ•°ï¼ˆåœ¨`launch_training.sh`ä¸­é…ç½®ï¼‰ï¼š
- `--dataset_name`: è®­ç»ƒæ•°æ®é›†åç§°
- `--epochs`: è®­ç»ƒè½®æ•°
- `--batch_size`: æ‰¹æ¬¡å¤§å°
- `--lr`: å­¦ä¹ ç‡
- `--beta`: KLæƒ©ç½šç³»æ•°
- `--temperature`: é‡‡æ ·æ¸©åº¦
- `--num_gen`: æ¯ä¸ªpromptç”Ÿæˆçš„æ ·æœ¬æ•°
- `--max_tokens`: æœ€å¤§ç”Ÿæˆé•¿åº¦

## æ³¨æ„äº‹é¡¹

1. ç¡®ä¿æ‰€æœ‰èŠ‚ç‚¹éƒ½èƒ½ç›¸äº’è®¿é—®
2. ç¡®ä¿æ¨¡å‹è·¯å¾„åœ¨æ‰€æœ‰èŠ‚ç‚¹ä¸Šéƒ½å­˜åœ¨
3. ç¡®ä¿æ‰€æœ‰èŠ‚ç‚¹çš„CUDAç¯å¢ƒæ­£ç¡®é…ç½®
4. ä½¿ç”¨ç›¸å¯¹è·¯å¾„è¿›è¡Œè¾“å‡ºï¼Œä¾¿äºè·¨èŠ‚ç‚¹å…±äº«